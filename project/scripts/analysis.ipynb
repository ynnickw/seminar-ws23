{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "import statements and general analysis setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from haralyzer import HarParser\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 100\n"
     ]
    }
   ],
   "source": [
    "host = \"bbc.com\"\n",
    "har_file_path = \"../archives/www.\" + host + \".har\"\n",
    "\n",
    "# Read the content of the HAR file and convert it to a dictionary\n",
    "with open(har_file_path, \"r\", encoding=\"utf-8\") as har_file:\n",
    "    har_data = json.load(har_file)\n",
    "\n",
    "har_parser = HarParser(har_data)\n",
    "entries = har_parser.har_data['entries']\n",
    "\n",
    "print(\"Number of entries: {}\".format(len(entries)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device Data in Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 100\n",
      "percentage of reqeuets with user agent: 100%\n",
      "\n",
      "All user agents:\n",
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\n"
     ]
    }
   ],
   "source": [
    "all_user_agents = []\n",
    "\n",
    "for entry in entries:\n",
    "    request = entry.get('request', {})\n",
    "    requestHeaders = request.get('headers', [])\n",
    "\n",
    "    # Analyze user agents\n",
    "    user_agent_header = next((header for header in requestHeaders if header['name'].lower() == 'user-agent'), None)\n",
    "    if user_agent_header:\n",
    "        user_agent_value = user_agent_header['value']\n",
    "        all_user_agents.append(user_agent_value)\n",
    "\n",
    "print(\"Count: \" + str(len(all_user_agents)))\n",
    "print(\"percentage of reqeuets with user agent: \" + str(round((len(all_user_agents) / len(entries) * 100))) + \"%\\n\")\n",
    "print(\"All user agents:\")\n",
    "for user_agent in list(set(all_user_agents)):\n",
    "    print(user_agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cookies\n",
    "find all set-cookie values in response headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set-Cookie: AWSALB=8hEzRFfYRCZnqciJVvGHP4dcN9jXX/AjZzm4NZiuSwzZ7YOmHnLUydAoWW6QCC6SLpeJDd6+O86YsY8bbe+SSlh2IiLByNZXgCCm8enRyg97Z9fT4qtF7b+VEWw+; Expires=Thu, 21 Dec 2023 18:52:04 GMT; Path=/\n",
      "Set-Cookie: AWSALBCORS=8hEzRFfYRCZnqciJVvGHP4dcN9jXX/AjZzm4NZiuSwzZ7YOmHnLUydAoWW6QCC6SLpeJDd6+O86YsY8bbe+SSlh2IiLByNZXgCCm8enRyg97Z9fT4qtF7b+VEWw+; Expires=Thu, 21 Dec 2023 18:52:04 GMT; Path=/; SameSite=None; Secure\n"
     ]
    }
   ],
   "source": [
    "for entry in entries:\n",
    "    response = entry.get('response', {})\n",
    "    responseHeaders = response.get('headers', [])\n",
    "\n",
    "    # Analyze cookies\n",
    "    for header in responseHeaders:\n",
    "        if header['name'].lower() == 'set-cookie':\n",
    "            cookies = header['value']\n",
    "            print(f\"Set-Cookie: {cookies}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Party Requests\n",
    "find requests to third party domains of all types except stylesheet, image and font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of requests: 70\n",
      "document -> edigitalsurvey.com\n",
      "script -> weather.files.bbci.co.uk\n",
      "script -> scripts.webcontentassessor.com\n",
      "script -> prebid.the-ozone-project.com\n",
      "script -> m.files.bbci.co.uk\n",
      "script -> emp.bbci.co.uk\n",
      "script -> static.files.bbci.co.uk\n",
      "other -> static.files.bbci.co.uk\n",
      "script -> assets.zephr.com\n",
      "script -> nav.files.bbci.co.uk\n",
      "preflight -> cdn.privacy-mgmt.com\n",
      "script -> static.bbci.co.uk\n",
      "script -> mybbc-analytics.files.bbci.co.uk\n",
      "script -> cdn.permutive.com\n",
      "script -> uk-script.dotmetrics.net\n",
      "fetch -> idcta.api.bbc.co.uk\n",
      "script -> securepubads.g.doubleclick.net\n",
      "script -> bbc.gscontxt.net\n",
      "script -> idcta.api.bbc.co.uk\n",
      "script -> sb.scorecardresearch.com\n",
      "script -> cdn.privacy-mgmt.com\n",
      "xhr -> cdn.privacy-mgmt.com\n",
      "fetch -> gn-flagpoles.api.bbci.co.uk\n",
      "script -> cdn.adsafeprotected.com\n"
     ]
    }
   ],
   "source": [
    "all_request_domains = []\n",
    "\n",
    "for entry in entries:\n",
    "    request = entry.get('request', {})\n",
    "    response = entry.get('response', {})\n",
    "\n",
    "    # Analyze third-party requests  \n",
    "    if 'url' in request:\n",
    "        request_url = urlparse(request['url']).hostname\n",
    "\n",
    "        if host not in request_url and entry['_resourceType'] != 'stylesheet' and entry['_resourceType'] != 'font' and entry['_resourceType'] != 'image':\n",
    "            all_request_domains.append(entry['_resourceType'] + \" -> \" + request_url)\n",
    "\n",
    "print(f\"Total number of requests: {len(all_request_domains)}\")\n",
    "for domain in list(set(all_request_domains)):\n",
    "    print(domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=1440\n",
      "body=%7B%22accountId%22%3A1786%2C%22campaignEnv%22%3A%22prod%22%2C%22campaigns%22%3A%7B%22ccpa%22%3A%7B%22alwaysDisplayDNS%22%3Afalse%2C%22status%22%3A%22rejectedNone%22%2C%22hasLocalData%22%3A36%2C%22targetingParams%22%3A%7B%7D%7D%2C%22gdpr%22%3A%7B%22consentStatus%22%3A%7B%22hasConsentData%22%3Atrue%2C%22consentedToAll%22%3Atrue%2C%22consentedToAny%22%3Atrue%2C%22rejectedAny%22%3Afalse%7D%2C%22hasLocalData%22%3Atrue%2C%22targetingParams%22%3A%7B%7D%7D%7D%2C%22clientMMSOrigin%22%3A%22https%3A%2F%2Fcdn.privacy-mgmt.com%22%2C%22hasCSP%22%3Atrue%2C%22includeData%22%3A%7B%22localState%22%3A%7B%22type%22%3A%22string%22%7D%2C%22actions%22%3A%7B%22type%22%3A%22RecordString%22%7D%2C%22cookies%22%3A%7B%22type%22%3A%22RecordString%22%7D%7D%2C%22propertyHref%22%3A%22https%3A%2F%2Fwww.bbc.com%2Fweather%22%7D\n",
      "ptrt=https://www.bbc.com/weather\n",
      "localState=%7B%22gdpr%22%3A%7B%22mmsCookies%22%3A%5B%22_sp_v1_ss%3D1%3AH4sIAAAAAAAAAItWqo5RKimOUbKKxsrIAzEMamN1YpRSQcy80pwcILsErKC6lgwJpVgAEA5-UnQAAAA%253D%22%5D%2C%22propertyId%22%3A26225%2C%22messageId%22%3A0%7D%2C%22ccpa%22%3A%7B%22mmsCookies%22%3A%5B%5D%2C%22propertyId%22%3A26225%2C%22messageId%22%3A0%7D%7D\n",
      "scriptType=unified\n",
      "v=7291\n",
      "d=www.bbc.com\n",
      "xdm_c=edr0\n",
      "userOrigin=WEATHER_GNL\n",
      "buttonSize=medium\n",
      "buttonColour=white\n",
      "hasCsp=true\n",
      "url=https%3A%2F%2Fwww.bbc.com%2Fweather\n",
      "ch=null\n",
      "xdm=edr\n",
      "ch=440052077440052077ef18\n",
      "nonKeyedLocalState=%7B%22ccpa%22%3A%7B%7D%2C%22gdpr%22%3A%7B%22_sp_v1_data%22%3A%22698930%22%2C%22_sp_v1_p%22%3A%22854%22%7D%7D\n",
      "p=%2Fweather\n",
      "ptrt=https%3A%2F%2Fwww.bbc.com%2Fweather%3Fzephr-REPLACETYPE\n",
      "t=weathergnl\n",
      "href=https%3A%2F%2Fwww.bbc.com%2Fweather\n",
      "c=null\n",
      "y=900\n",
      "ck=1\n",
      "propertyId=26225\n",
      "callback=\n",
      "accountId=1786\n",
      "d=30\n",
      "metadata=%7B%22ccpa%22%3A%7B%22applies%22%3Afalse%7D%2C%22gdpr%22%3A%7B%22applies%22%3Atrue%7D%7D\n",
      "xdm_o=https%3A%2F%2Fwww.bbc.com\n",
      "account_id=1786\n",
      "id=INS-vt29-666188954\n",
      "scriptVersion=4.13.4\n",
      "ptrt=https%3A%2F%2Fwww.bbc.com%2Fweather\n",
      "lang=en-GB\n",
      "metadata=%7B%22ccpa%22%3A%7B%7D%2C%22gdpr%22%3A%7B%7D%7D\n",
      "fu=https%3A%2F%2Fwww.bbc.com%2Fweather\n",
      "userOrigin=weather_gnl\n",
      "ref=https%3A%2F%2Fwww.bbc.co.uk%2F\n",
      "env=prod\n"
     ]
    }
   ],
   "source": [
    "all_query_strings = []\n",
    "\n",
    "for entry in entries:\n",
    "    request = entry.get('request', {})\n",
    "\n",
    "    # Analyze query strings\n",
    "    if 'queryString' in request:\n",
    "        query_string_list = request['queryString']\n",
    "        if query_string_list:\n",
    "            # Extract query strings from the list\n",
    "            query_strings = [param['name'] + '=' + param['value'] for param in query_string_list]\n",
    "            all_query_strings.extend(query_strings)\n",
    "\n",
    "\n",
    "# Print or use unique_query_strings as needed\n",
    "for query_string in list(set(all_query_strings)):\n",
    "    print(query_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contains test mail\n",
    "check if any request contains aSHA256 or base64 endcoded version of our test mail address or password"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seminar-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
